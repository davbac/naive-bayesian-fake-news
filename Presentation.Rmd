---
title: "Naive Bayes Classifier"
author: "Bacilieri Davide, Barbiero Lorenzo"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
set.seed(12345)
```


# Naive Bayesian Classifier for Fake News Recognition

Naive Bayesian Classifiers (NLPs) are statistical tools used in text classification.
Borrowing from the Machine Learning jargon they work in the field of SUpervised Learning (Data + Labels) but, contrairly to most solutions in the field on NLP (Natural Language Processing) the do not involve the infamous backpropagation present in Neural Network and can thus be trained much faster

### How do they work?

In the broadest sense they work by applying iteratively the Bayes theorem in the following way
$P(c|d) \propto P(d|c)P(c)$
Where $d$ is the document, to be intended as a list of words and $c$ is the class of that document.

#### Prior
The most common choice for the prior is to consider it as the fraction of documents belonging to the class in the dataset
$P(class=c)=\frac{N_c}{N}$

#### Likelihood
There are several possible choices for the likelihood but the two most common ones are

- Multinomial
- Bernoulli

Dave please add details

After some tests with the dataset we noticed very similar performance for both methods but a much faster computation for the Multinomial one so we focused on it

## The Data
The dataset is available on Kaggle as a .csv file, we can import and arrange it

```{r}
data <- read.csv('archive/train.csv', header=TRUE)

head(data)
```

In our case the 
## Multinomial



### First results
Running the learner "as is" provides the following results

```{r}
test_perc <- 0.8

data <- read.csv('archive/train.csv')

length(data[,"Labels"])
data <- data[sample(1:length(data$Labels)), ] #random shuffle
length(data[,"Labels"])
val_data <- data[as.integer(test_perc * length(data$Labels)):length(data$Labels),]
data <- data[1:as.integer(test_perc * length(data$Labels)),]
length(data[,"Labels"])
length(val_data[,"Labels"])
```


```{r}
pc <- c(0,0,0,0,0,0)
for(i in 0:5) {
    pc[i+1] <- length(data[data[, "Labels"]==i, "Labels"])
}

full_text <- paste(data$Text, sep=" ", collapse=" ")
tokens <- unique(strsplit(full_text, " ")[[1]])
tokens <- tokens[- (tokens=="")]

## multinomial model
ptc <- data.frame(
    token = tokens, 
    ct0 = 0,
    ct1 = 0,
    ct2 = 0,
    ct3 = 0,
    ct4 = 0,
    ct5 = 0,
    pt0 = 0,
    pt1 = 0,
    pt2 = 0,
    pt3 = 0,
    pt4 = 0,
    pt5 = 0
)



for(i in 0:5) {
    class_text <- strsplit(paste(data[data[, "Labels"]==i, "Text"], sep=" ", collapse=" "), " ")[[1]]
    
    for(j in 1:length(tokens)) {
        ptc[j,paste("ct",i, sep="")] <- sum(class_text==ptc[j, "token"]) + 1
    }
    ptc[,paste("pt",i, sep="")] <- ptc[,paste("ct",i, sep="")] / (length(class_text) + length(tokens))
}

ptc <- ptc[,c("token","pt0", "pt1", "pt2", "pt3", "pt4", "pt5")]



right_tr <- 0
right_test <- 0

  for(k in 1:length(data[,"Labels"])) {
      vec <- strsplit(data[k, "Text"], " ")[[1]]
     probs <- log(pc)

    
      for(h in vec) {
        for(i in 0:5) {
            inc <- log(ptc[ptc[,"token"]==h ,paste("pt",i, sep="")])
            if ( length(inc) == 1 && ! any(is.na(inc)) ) {
                probs[i+1] <- probs[i+1] + inc
            }
        }
    }

    
      if( (0:5)[probs == max(probs)] == data[k, "Labels"]) {
          right_tr <- right_tr + 1
        
      }

  }

  acc_train <- 100*right_tr/length(data[,"Labels"])
  
    for(k in 1:length(val_data[,"Labels"])) {
      vec <- strsplit(val_data[k, "Text"], " ")[[1]]
     probs <- log(pc)

    
      for(h in vec) {
        for(i in 0:5) {
            inc <- log(ptc[ptc[,"token"]==h ,paste("pt",i, sep="")])
            if ( length(inc) == 1 && ! any(is.na(inc)) ) {
                probs[i+1] <- probs[i+1] + inc
            }
        }
    }

    
      if( (0:5)[probs == max(probs)] == val_data[k, "Labels"]) {
          right_test <- right_test + 1
        
      }

  }

  acc_test <- 100*right_test/length(val_data[,"Labels"])
```

Accuracy on training set
```{r}
acc_train
```

Accuracy on test set
```{r}
acc_test
```
As we can see accuracy is really satisfactory on the training set, however in the test set accuracy is only marginally better than random choice (16.7%). This is a clear case of overfitting, that is, the learner is learning to replicate the training dataset and he's not learning the important features

## Feature selection

First of all, some processing and formatting is needed, to be specific:
  - words are converted to lowercase
  - punctuation is removed
  - words are counted by class
  
```{r}
df <- data.frame(data)

# Convert everything to lowercase, remove punctuation, and split into separate words
df <- df |> mutate(Text = tolower(Text)) |>
  mutate(Text = str_replace_all(Text, "[[:punct:]]", ""))
  

# Count the occurrences of each word for each label
word_counts <- df |>
  separate_rows(Text, sep = "\\s+") |>
  group_by(Labels, Text) |>
  summarise(count = n()) |>
  arrange(-count)

# Reformat the word_counts data frame
reformatted_word_counts <- word_counts %>%
  pivot_wider(names_from = Labels, values_from = count, values_fill = 0)%>%
  mutate(Sum = rowSums(across(-Text))) |> arrange(-Sum)

colnames(reformatted_word_counts) <- c("Text","Two","Three","One","Five","Zero","Four", "Total")

# Print the reformatted word counts
head(reformatted_word_counts)
(nrow(reformatted_word_counts))
```
The dataset now features
```{r}
(nrow(reformatted_word_counts))
```
words


### Frequency Based Feature selection

Before implementing fancier feature selection methods we will filer out the words that appear less than a certain amount of times, this is useful to remove outliers, both in the forms of grammatical or formatting errors as well as terms that skew prediction

```{r}
# Minimum count threshold
min_count <- 2

# Filter out rows with counts below the threshold
filtered_word_counts <- reformatted_word_counts %>%
  filter(Total > min_count) 
```

With this simple step the dataset size is reduced to

```{r}
(nrow(filtered_word_counts))
```

### Information based feature selection

#### Mutual Information

```{r}
mutual_info <- function(N_11,N_01,N_10,N_00){
  N <- N_00+N_01+N_10+N_11
  N_1. <- N_01+N_11
  N_.1 <- N_10+N_11
  N_0. <- N_00+N_10
  N_.0 <- N_01+N_00
  
  info <- (N_11/N)*log2(N*N_11/(N_1.*N_.1)) + 
                   (N_10/N)*log2(N*N_10/(N_0.*N_.1)) + 
                   (N_01/N)*log2(N*N_01/(N_1.*N_.0)) +
                   (N_00/N)*log2(N*N_00/(N_0.*N_.0))

  return(info)
}
```

#### Chi Squared

```{r}
chi2 <- function(N_11,N_01,N_10,N_00){
  N <- sum(N_00,N_10,N_11,N_01)
  E_11 <- (N_11+N_10)*(N_11+N_01)/N
  E_01 <- (N_01+N_11)*(N_01+N_00)/N
  E_10 <- (N_10+N_11)*(N_10+N_00)/N
  E_00 <- (N_00+N_10)*(N_00+N_01)/N
  
  chi <- sum((N_11-E_11)**2/E_11,(N_10-E_10)**2/E_10,(N_01-E_01)**2/E_01,(N_00-E_00)**2/E_00)
  
 return(chi) 
}
```

#### Computation

The first step is to compute the indicator of choice for the whole dataset

```{r}

select_method <- 0

# Create a Vector with Columns
columns = c("Text","Two","Three","One","Five","Zero","Four")
col_order = c("Text","Two","Three","One","Five","Zero","Four")

#Create a Empty DataFrame with 0 rows and n columns
results = data.frame(matrix(nrow = nrow(filtered_word_counts), ncol = length(columns))) 

# Assign column names
colnames(results) = columns

# Add word column
results$Text <- filtered_word_counts$Text


col_ind <- c("Two","Three","One","Five","Zero","Four")
row_ind <- c(1:nrow(filtered_word_counts))

for (y in col_ind) {
  dummydf <- filtered_word_counts[,c("Text",y,"Total")]
  for (x in row_ind) {
    N_11 <- as.numeric(dummydf[x,2])
    N_01 <- as.numeric(sum(dummydf[-x,2])) 
    N_10 <- as.numeric(dummydf[x,3] - dummydf[x,2]) 
    N_00 <- as.numeric(sum(dummydf[-x,3]-dummydf[-x,2])) 
    
    if (select_method == 1) {
      results[x,y] <- chi2(N_11,N_01,N_10,N_00)
    }
    else {
      results[x,y] <- mutual_info(N_11,N_01,N_10,N_00)
    }
  }
}

head(results)
```

The most relevant features will be selected as the fraction with the higher % of relevance for all classes

```{r}
top_percentage <- 0.1

col_ind <- c("Two","Three","One","Five","Zero","Four")

wrds <- vector()

for (y in col_ind) {
  dummydf <- results[,c("Text",y)]
  
  # Select rows with results in the top A%
  
  selected_rows <- dummydf %>%
  slice_max(dummydf[[2]] ,prop = top_percentage)
  rws <- as.vector(selected_rows$Text)
  wrds <- union(wrds,rws)
}
wrds <- wrds[order(-str_length(wrds))]
(length(wrds))
```


#### Reformat dataset

Finally, only these selected words are used in the analysis

```{r}
filter_words <- function(string, word_list) {
  # Split the string into individual words
  words <- strsplit(string, " ")[[1]]
  
  # Filter the words based on the match with the word list
  matched_words <- words[words %in% word_list]
  
  # Combine the matched words into a single string
  result <- paste(matched_words, collapse = " ")
  
  return(result)
}
```

```{r}
dfout <- df

for (i in c(1:nrow(dfout))) {
  dfout[i,2] <- filter_words(dfout[i,2],wrds)
}

(head(dfout[,2]))
(head(df[,2]))
```
Performing the analysis again yelds

```{r}
data <- dfout

length(data[,"Labels"])
length(val_data[,"Labels"])

pc <- c(0,0,0,0,0,0)
for(i in 0:5) {
    pc[i+1] <- length(data[data[, "Labels"]==i, "Labels"])
}

full_text <- paste(data$Text, sep=" ", collapse=" ")
tokens <- unique(strsplit(full_text, " ")[[1]])
tokens <- tokens[- (tokens=="")]

## multinomial model
ptc <- data.frame(
    token = tokens, 
    ct0 = 0,
    ct1 = 0,
    ct2 = 0,
    ct3 = 0,
    ct4 = 0,
    ct5 = 0,
    pt0 = 0,
    pt1 = 0,
    pt2 = 0,
    pt3 = 0,
    pt4 = 0,
    pt5 = 0
)



for(i in 0:5) {
    class_text <- strsplit(paste(data[data[, "Labels"]==i, "Text"], sep=" ", collapse=" "), " ")[[1]]
    
    for(j in 1:length(tokens)) {
        ptc[j,paste("ct",i, sep="")] <- sum(class_text==ptc[j, "token"]) + 1
    }
    ptc[,paste("pt",i, sep="")] <- ptc[,paste("ct",i, sep="")] / (length(class_text) + length(tokens))
}

ptc <- ptc[,c("token","pt0", "pt1", "pt2", "pt3", "pt4", "pt5")]



right_tr <- 0
right_test <- 0

  for(k in 1:length(data[,"Labels"])) {
      vec <- strsplit(data[k, "Text"], " ")[[1]]
     probs <- log(pc)

    
      for(h in vec) {
        for(i in 0:5) {
            inc <- log(ptc[ptc[,"token"]==h ,paste("pt",i, sep="")])
            if ( length(inc) == 1 && ! any(is.na(inc)) ) {
                probs[i+1] <- probs[i+1] + inc
            }
        }
    }

    
      if( (0:5)[probs == max(probs)] == data[k, "Labels"]) {
          right_tr <- right_tr + 1
        
      }

  }

  acc_train <- 100*right_tr/length(data[,"Labels"])
  
    for(k in 1:length(val_data[,"Labels"])) {
      vec <- strsplit(val_data[k, "Text"], " ")[[1]]
     probs <- log(pc)

    
      for(h in vec) {
        for(i in 0:5) {
            inc <- log(ptc[ptc[,"token"]==h ,paste("pt",i, sep="")])
            if ( length(inc) == 1 && ! any(is.na(inc)) ) {
                probs[i+1] <- probs[i+1] + inc
            }
        }
    }

    
      if( (0:5)[probs == max(probs)] == val_data[k, "Labels"]) {
          right_test <- right_test + 1
        
      }

  }

  acc_test <- 100*right_test/length(val_data[,"Labels"])
```

Accuracy on training set
```{r}
acc_train
```

Accuracy on test set
```{r}
acc_test
```


### Performance

We now need to optimize parameters to maximize the success rate

```{r}
benchmark <- function(minimum_counts, percentage, information_method){
 
  Min_Counts <- vector()
  Info_Perc <- vector()
  Info_Ret <- vector()
  Accuracy <- vector() 
   
  for (mct in minimum_counts) {
    for (prc in percentage) {
      for (ifm in infmet) {
        
  # Minimum count threshold
  min_count <- mct

  # Filter out rows with counts below the threshold
  filtered_word_counts <- reformatted_word_counts %>%
  filter(Total > min_count) 
  
  
  
  # Create a Vector with Columns
  columns = c("Text","Two","Three","One","Five","Zero","Four")
  #Create a Empty DataFrame with 0 rows and n columns
  results = data.frame(matrix(nrow = nrow(filtered_word_counts), ncol = length(columns))) 
  # Assign column names
  colnames(results) = columns
  # Add word column
  results$Text <- filtered_word_counts$Text
  
  
  
  select_method <- ifm

  col_ind <- c("Two","Three","One","Five","Zero","Four")
  row_ind <- c(1:nrow(filtered_word_counts))

  for (y in col_ind) {
    dummydf <- filtered_word_counts[,c("Text",y,"Total")]
    for (x in row_ind) {
      N_11 <- as.numeric(dummydf[x,2])
      N_01 <- as.numeric(sum(dummydf[-x,2])) 
      N_10 <- as.numeric(dummydf[x,3] - dummydf[x,2]) 
      N_00 <- as.numeric(sum(dummydf[-x,3]-dummydf[-x,2])) 
    
      if (select_method == 1) {
        results[x,y] <- chi2(N_11,N_01,N_10,N_00)
        metstring <- "Chi^2"
      }
      else if (select_method == 0) {
        results[x,y] <- mutual_info(N_11,N_01,N_10,N_00)
        metstring <- "MutInf"
      }
    }
  }
  


  wrds <- vector()

  for (y in col_ind) {
    dummydf <- results[,c("Text",y)]
  
    # Select rows with results in the top A%
    top_percentage <- prc

    selected_rows <- dummydf %>%
    slice_max(dummydf[[2]] ,prop = top_percentage)
    rws <- as.vector(selected_rows$Text)
    wrds <- union(wrds,rws)
  }
  wrds <- wrds[order(-str_length(wrds))]
  
  dfout <- df

  for (i in c(1:nrow(dfout))) {
    dfout[i,2] <- filter_words(dfout[i,2],wrds)
    }
  
  
  data <- dfout

  length(data[,"Labels"])
  data <- data[sample(1:length(data$Labels)), ] #random shuffle
  length(data[,"Labels"])
  val_data <- data[as.integer(test_perc * length(data$Labels)):length(data$Labels),]
  data <- data[1:as.integer(test_perc * length(data$Labels)),]
  length(data[,"Labels"])
  length(val_data[,"Labels"])
  
  pc <- c(0,0,0,0,0,0)
  for(i in 0:5) {
      pc[i+1] <- length(data[data[, "Labels"]==i, "Labels"])
  }

  full_text <- paste(data$Text, sep=" ", collapse=" ")
  tokens <- unique(strsplit(full_text, " ")[[1]])
  tokens <- tokens[- (tokens=="")]
  
  ptc <- data.frame(
    token = tokens, 
    ct0 = 0,
    ct1 = 0,
    ct2 = 0,
    ct3 = 0,
    ct4 = 0,
    ct5 = 0,
    pt0 = 0,
    pt1 = 0,
    pt2 = 0,
    pt3 = 0,
    pt4 = 0,
    pt5 = 0
    )



  for(i in 0:5) {
      class_text <- strsplit(paste(data[data[, "Labels"]==i, "Text"], sep=" ", collapse=" "), " ")[[1]]
      
      for(j in 1:length(tokens)) {
          ptc[j,paste("ct",i, sep="")] <- sum(class_text==ptc[j, "token"]) + 1
    }
    ptc[,paste("pt",i, sep="")] <- ptc[,paste("ct",i, sep="")] / (length(class_text) + length(tokens))
  }

  ptc <- ptc[,c("token","pt0", "pt1", "pt2", "pt3", "pt4", "pt5")]

  
  
    right <- 0

  for(k in 1:length(val_data[,"Labels"])) {
      vec <- strsplit(val_data[k, "Text"], " ")[[1]]
     probs <- log(pc)

    
      for(h in vec) {
        for(i in 0:5) {
            inc <- log(ptc[ptc[,"token"]==h ,paste("pt",i, sep="")])
            if ( length(inc) == 1 && ! any(is.na(inc)) ) {
                probs[i+1] <- probs[i+1] + inc
            }
        }
    }

    
      if( (0:5)[probs == max(probs)] == val_data[k, "Labels"]) {
          right <- right + 1
        
      }

  }

  acc <- 100*right/length(val_data[,"Labels"])



  result <- paste("min_counts: ",min_count," info_percentage: ",top_percentage, "info_ret_method: ", metstring, " Accuracy%: ", acc)
  print(result)
  
  Min_Counts <- append(Min_Counts,min_count)
  Info_Perc <- append(Info_Perc,top_percentage)
  Info_Ret <- append(Info_Ret,metstring)
  Accuracy <- append(Accuracy,acc)
  
      }
    }
  }
  
  bench <- data.frame(Min_Counts,Info_Perc,Info_Ret,Accuracy)
  
  # Create a Vector with Columns
  columns = c("min_counts","info_percentage","info_ret_method","Accuracy")
  
  # Assign column names
  colnames(bench) = columns
  
  return(bench)
}
```

```{r}
min_cts <- c(1,2,5)
perc <- c(0.01,0.03,0.05,0.1,0.3)
infmet <- c(0,1)

bench <- benchmark(minimum_counts = min_cts,percentage = perc,information_method = infmet)
```

